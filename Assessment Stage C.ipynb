{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hamoye Data Science Internship (Stage-C)\n",
    "## Name:- Manoj Kumar M P"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instructions for Tag-Along Project\n",
    "Stability of the Grid System**\n",
    "\n",
    "Electrical grids require a balance between electricity supply and demand in order to be stable. Conventional systems achieve this balance through demand-driven electricity production. For future grids with a high share of inflexible (i.e., renewable) energy sources, the concept of demand response is a promising solution. This implies changes in electricity consumption in relation to electricity price changes. In this work, we’ll build a binary classification model to predict if a grid is stable or unstable using the UCI Electrical Grid Stability Simulated dataset.<br>\n",
    "\n",
    "Dataset: https://archive.ics.uci.edu/ml/datasets/Electrical+Grid+Stability+Simulated+Data+\n",
    "\n",
    "It has 12 primary predictive features and two dependent variables.<br>\n",
    "\n",
    "Predictive features:<br>\n",
    "\n",
    "'tau1' to 'tau4': the reaction time of each network participant, a real value within the range 0.5 to 10 ('tau1' corresponds to the supplier node, 'tau2' to 'tau4' to the consumer nodes);<br>\n",
    "\n",
    "'p1' to 'p4': nominal power produced (positive) or consumed (negative) by each network participant, a real value within the range -2.0 to -0.5 for consumers ('p2' to 'p4'). As the total power consumed equals the total power generated, p1 (supplier node) = - (p2 + p3 + p4);<br>\n",
    "\n",
    "'g1' to 'g4': price elasticity coefficient for each network participant, a real value within the range 0.05 to 1.00 ('g1' corresponds to the supplier node, 'g2' to 'g4' to the consumer nodes; 'g' stands for 'gamma');\n",
    "Dependent variables:<br>\n",
    "\n",
    "'stab': the maximum real part of the characteristic differential equation root (if positive, the system is linearly unstable; if negative, linearly stable);<br>\n",
    "\n",
    "'stabf': a categorical (binary) label ('stable' or 'unstable').<br>\n",
    "\n",
    "Because of the direct relationship between 'stab' and 'stabf' ('stabf' = 'stable' if 'stab' <= 0, 'unstable' otherwise), 'stab' should be dropped and 'stabf' will remain as the sole dependent variable (binary classification).<br>\n",
    "\n",
    "Split the data into an 80-20 train-test split with a random state of “1”.<br>\n",
    "Use the standard scaler to transform the train set (x_train, y_train) and the test set (x_test). <br>\n",
    "Use scikit learn to train a random forest and extra trees classifier. <br>\n",
    "And use xgboost and lightgbm to train an extreme boosting model and a light gradient boosting model. <br>\n",
    "Use random_state = 1 for training all models and evaluate on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the necessary libraries\n",
    "\n",
    "import pandas as pd\n",
    "import lightgbm as lgbm\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV \n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier \n",
    "from sklearn.metrics import recall_score, accuracy_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tau1</th>\n",
       "      <th>tau2</th>\n",
       "      <th>tau3</th>\n",
       "      <th>tau4</th>\n",
       "      <th>p1</th>\n",
       "      <th>p2</th>\n",
       "      <th>p3</th>\n",
       "      <th>p4</th>\n",
       "      <th>g1</th>\n",
       "      <th>g2</th>\n",
       "      <th>g3</th>\n",
       "      <th>g4</th>\n",
       "      <th>stab</th>\n",
       "      <th>stabf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.959060</td>\n",
       "      <td>3.079885</td>\n",
       "      <td>8.381025</td>\n",
       "      <td>9.780754</td>\n",
       "      <td>3.763085</td>\n",
       "      <td>-0.782604</td>\n",
       "      <td>-1.257395</td>\n",
       "      <td>-1.723086</td>\n",
       "      <td>0.650456</td>\n",
       "      <td>0.859578</td>\n",
       "      <td>0.887445</td>\n",
       "      <td>0.958034</td>\n",
       "      <td>0.055347</td>\n",
       "      <td>unstable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.304097</td>\n",
       "      <td>4.902524</td>\n",
       "      <td>3.047541</td>\n",
       "      <td>1.369357</td>\n",
       "      <td>5.067812</td>\n",
       "      <td>-1.940058</td>\n",
       "      <td>-1.872742</td>\n",
       "      <td>-1.255012</td>\n",
       "      <td>0.413441</td>\n",
       "      <td>0.862414</td>\n",
       "      <td>0.562139</td>\n",
       "      <td>0.781760</td>\n",
       "      <td>-0.005957</td>\n",
       "      <td>stable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.971707</td>\n",
       "      <td>8.848428</td>\n",
       "      <td>3.046479</td>\n",
       "      <td>1.214518</td>\n",
       "      <td>3.405158</td>\n",
       "      <td>-1.207456</td>\n",
       "      <td>-1.277210</td>\n",
       "      <td>-0.920492</td>\n",
       "      <td>0.163041</td>\n",
       "      <td>0.766689</td>\n",
       "      <td>0.839444</td>\n",
       "      <td>0.109853</td>\n",
       "      <td>0.003471</td>\n",
       "      <td>unstable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.716415</td>\n",
       "      <td>7.669600</td>\n",
       "      <td>4.486641</td>\n",
       "      <td>2.340563</td>\n",
       "      <td>3.963791</td>\n",
       "      <td>-1.027473</td>\n",
       "      <td>-1.938944</td>\n",
       "      <td>-0.997374</td>\n",
       "      <td>0.446209</td>\n",
       "      <td>0.976744</td>\n",
       "      <td>0.929381</td>\n",
       "      <td>0.362718</td>\n",
       "      <td>0.028871</td>\n",
       "      <td>unstable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.134112</td>\n",
       "      <td>7.608772</td>\n",
       "      <td>4.943759</td>\n",
       "      <td>9.857573</td>\n",
       "      <td>3.525811</td>\n",
       "      <td>-1.125531</td>\n",
       "      <td>-1.845975</td>\n",
       "      <td>-0.554305</td>\n",
       "      <td>0.797110</td>\n",
       "      <td>0.455450</td>\n",
       "      <td>0.656947</td>\n",
       "      <td>0.820923</td>\n",
       "      <td>0.049860</td>\n",
       "      <td>unstable</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       tau1      tau2      tau3      tau4        p1        p2        p3  \\\n",
       "0  2.959060  3.079885  8.381025  9.780754  3.763085 -0.782604 -1.257395   \n",
       "1  9.304097  4.902524  3.047541  1.369357  5.067812 -1.940058 -1.872742   \n",
       "2  8.971707  8.848428  3.046479  1.214518  3.405158 -1.207456 -1.277210   \n",
       "3  0.716415  7.669600  4.486641  2.340563  3.963791 -1.027473 -1.938944   \n",
       "4  3.134112  7.608772  4.943759  9.857573  3.525811 -1.125531 -1.845975   \n",
       "\n",
       "         p4        g1        g2        g3        g4      stab     stabf  \n",
       "0 -1.723086  0.650456  0.859578  0.887445  0.958034  0.055347  unstable  \n",
       "1 -1.255012  0.413441  0.862414  0.562139  0.781760 -0.005957    stable  \n",
       "2 -0.920492  0.163041  0.766689  0.839444  0.109853  0.003471  unstable  \n",
       "3 -0.997374  0.446209  0.976744  0.929381  0.362718  0.028871  unstable  \n",
       "4 -0.554305  0.797110  0.455450  0.656947  0.820923  0.049860  unstable  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing the data\n",
    "\n",
    "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/00471/Data_for_UCI_named.csv'\n",
    "df = pd.read_csv(url)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   tau1    10000 non-null  float64\n",
      " 1   tau2    10000 non-null  float64\n",
      " 2   tau3    10000 non-null  float64\n",
      " 3   tau4    10000 non-null  float64\n",
      " 4   p1      10000 non-null  float64\n",
      " 5   p2      10000 non-null  float64\n",
      " 6   p3      10000 non-null  float64\n",
      " 7   p4      10000 non-null  float64\n",
      " 8   g1      10000 non-null  float64\n",
      " 9   g2      10000 non-null  float64\n",
      " 10  g3      10000 non-null  float64\n",
      " 11  g4      10000 non-null  float64\n",
      " 12  stab    10000 non-null  float64\n",
      " 13  stabf   10000 non-null  object \n",
      "dtypes: float64(13), object(1)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tau1     0\n",
       "tau2     0\n",
       "tau3     0\n",
       "tau4     0\n",
       "p1       0\n",
       "p2       0\n",
       "p3       0\n",
       "p4       0\n",
       "g1       0\n",
       "g2       0\n",
       "g3       0\n",
       "g4       0\n",
       "stab     0\n",
       "stabf    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tau1</th>\n",
       "      <th>tau2</th>\n",
       "      <th>tau3</th>\n",
       "      <th>tau4</th>\n",
       "      <th>p1</th>\n",
       "      <th>p2</th>\n",
       "      <th>p3</th>\n",
       "      <th>p4</th>\n",
       "      <th>g1</th>\n",
       "      <th>g2</th>\n",
       "      <th>g3</th>\n",
       "      <th>g4</th>\n",
       "      <th>stab</th>\n",
       "      <th>stabf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.959060</td>\n",
       "      <td>3.079885</td>\n",
       "      <td>8.381025</td>\n",
       "      <td>9.780754</td>\n",
       "      <td>3.763085</td>\n",
       "      <td>-0.782604</td>\n",
       "      <td>-1.257395</td>\n",
       "      <td>-1.723086</td>\n",
       "      <td>0.650456</td>\n",
       "      <td>0.859578</td>\n",
       "      <td>0.887445</td>\n",
       "      <td>0.958034</td>\n",
       "      <td>0.055347</td>\n",
       "      <td>unstable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.304097</td>\n",
       "      <td>4.902524</td>\n",
       "      <td>3.047541</td>\n",
       "      <td>1.369357</td>\n",
       "      <td>5.067812</td>\n",
       "      <td>-1.940058</td>\n",
       "      <td>-1.872742</td>\n",
       "      <td>-1.255012</td>\n",
       "      <td>0.413441</td>\n",
       "      <td>0.862414</td>\n",
       "      <td>0.562139</td>\n",
       "      <td>0.781760</td>\n",
       "      <td>-0.005957</td>\n",
       "      <td>stable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.971707</td>\n",
       "      <td>8.848428</td>\n",
       "      <td>3.046479</td>\n",
       "      <td>1.214518</td>\n",
       "      <td>3.405158</td>\n",
       "      <td>-1.207456</td>\n",
       "      <td>-1.277210</td>\n",
       "      <td>-0.920492</td>\n",
       "      <td>0.163041</td>\n",
       "      <td>0.766689</td>\n",
       "      <td>0.839444</td>\n",
       "      <td>0.109853</td>\n",
       "      <td>0.003471</td>\n",
       "      <td>unstable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.716415</td>\n",
       "      <td>7.669600</td>\n",
       "      <td>4.486641</td>\n",
       "      <td>2.340563</td>\n",
       "      <td>3.963791</td>\n",
       "      <td>-1.027473</td>\n",
       "      <td>-1.938944</td>\n",
       "      <td>-0.997374</td>\n",
       "      <td>0.446209</td>\n",
       "      <td>0.976744</td>\n",
       "      <td>0.929381</td>\n",
       "      <td>0.362718</td>\n",
       "      <td>0.028871</td>\n",
       "      <td>unstable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.134112</td>\n",
       "      <td>7.608772</td>\n",
       "      <td>4.943759</td>\n",
       "      <td>9.857573</td>\n",
       "      <td>3.525811</td>\n",
       "      <td>-1.125531</td>\n",
       "      <td>-1.845975</td>\n",
       "      <td>-0.554305</td>\n",
       "      <td>0.797110</td>\n",
       "      <td>0.455450</td>\n",
       "      <td>0.656947</td>\n",
       "      <td>0.820923</td>\n",
       "      <td>0.049860</td>\n",
       "      <td>unstable</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       tau1      tau2      tau3      tau4        p1        p2        p3  \\\n",
       "0  2.959060  3.079885  8.381025  9.780754  3.763085 -0.782604 -1.257395   \n",
       "1  9.304097  4.902524  3.047541  1.369357  5.067812 -1.940058 -1.872742   \n",
       "2  8.971707  8.848428  3.046479  1.214518  3.405158 -1.207456 -1.277210   \n",
       "3  0.716415  7.669600  4.486641  2.340563  3.963791 -1.027473 -1.938944   \n",
       "4  3.134112  7.608772  4.943759  9.857573  3.525811 -1.125531 -1.845975   \n",
       "\n",
       "         p4        g1        g2        g3        g4      stab     stabf  \n",
       "0 -1.723086  0.650456  0.859578  0.887445  0.958034  0.055347  unstable  \n",
       "1 -1.255012  0.413441  0.862414  0.562139  0.781760 -0.005957    stable  \n",
       "2 -0.920492  0.163041  0.766689  0.839444  0.109853  0.003471  unstable  \n",
       "3 -0.997374  0.446209  0.976744  0.929381  0.362718  0.028871  unstable  \n",
       "4 -0.554305  0.797110  0.455450  0.656947  0.820923  0.049860  unstable  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tau1</th>\n",
       "      <th>tau2</th>\n",
       "      <th>tau3</th>\n",
       "      <th>tau4</th>\n",
       "      <th>p1</th>\n",
       "      <th>p2</th>\n",
       "      <th>p3</th>\n",
       "      <th>p4</th>\n",
       "      <th>g1</th>\n",
       "      <th>g2</th>\n",
       "      <th>g3</th>\n",
       "      <th>g4</th>\n",
       "      <th>stabf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.959060</td>\n",
       "      <td>3.079885</td>\n",
       "      <td>8.381025</td>\n",
       "      <td>9.780754</td>\n",
       "      <td>3.763085</td>\n",
       "      <td>-0.782604</td>\n",
       "      <td>-1.257395</td>\n",
       "      <td>-1.723086</td>\n",
       "      <td>0.650456</td>\n",
       "      <td>0.859578</td>\n",
       "      <td>0.887445</td>\n",
       "      <td>0.958034</td>\n",
       "      <td>unstable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.304097</td>\n",
       "      <td>4.902524</td>\n",
       "      <td>3.047541</td>\n",
       "      <td>1.369357</td>\n",
       "      <td>5.067812</td>\n",
       "      <td>-1.940058</td>\n",
       "      <td>-1.872742</td>\n",
       "      <td>-1.255012</td>\n",
       "      <td>0.413441</td>\n",
       "      <td>0.862414</td>\n",
       "      <td>0.562139</td>\n",
       "      <td>0.781760</td>\n",
       "      <td>stable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.971707</td>\n",
       "      <td>8.848428</td>\n",
       "      <td>3.046479</td>\n",
       "      <td>1.214518</td>\n",
       "      <td>3.405158</td>\n",
       "      <td>-1.207456</td>\n",
       "      <td>-1.277210</td>\n",
       "      <td>-0.920492</td>\n",
       "      <td>0.163041</td>\n",
       "      <td>0.766689</td>\n",
       "      <td>0.839444</td>\n",
       "      <td>0.109853</td>\n",
       "      <td>unstable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.716415</td>\n",
       "      <td>7.669600</td>\n",
       "      <td>4.486641</td>\n",
       "      <td>2.340563</td>\n",
       "      <td>3.963791</td>\n",
       "      <td>-1.027473</td>\n",
       "      <td>-1.938944</td>\n",
       "      <td>-0.997374</td>\n",
       "      <td>0.446209</td>\n",
       "      <td>0.976744</td>\n",
       "      <td>0.929381</td>\n",
       "      <td>0.362718</td>\n",
       "      <td>unstable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.134112</td>\n",
       "      <td>7.608772</td>\n",
       "      <td>4.943759</td>\n",
       "      <td>9.857573</td>\n",
       "      <td>3.525811</td>\n",
       "      <td>-1.125531</td>\n",
       "      <td>-1.845975</td>\n",
       "      <td>-0.554305</td>\n",
       "      <td>0.797110</td>\n",
       "      <td>0.455450</td>\n",
       "      <td>0.656947</td>\n",
       "      <td>0.820923</td>\n",
       "      <td>unstable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>2.930406</td>\n",
       "      <td>9.487627</td>\n",
       "      <td>2.376523</td>\n",
       "      <td>6.187797</td>\n",
       "      <td>3.343416</td>\n",
       "      <td>-0.658054</td>\n",
       "      <td>-1.449106</td>\n",
       "      <td>-1.236256</td>\n",
       "      <td>0.601709</td>\n",
       "      <td>0.779642</td>\n",
       "      <td>0.813512</td>\n",
       "      <td>0.608385</td>\n",
       "      <td>unstable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>3.392299</td>\n",
       "      <td>1.274827</td>\n",
       "      <td>2.954947</td>\n",
       "      <td>6.894759</td>\n",
       "      <td>4.349512</td>\n",
       "      <td>-1.663661</td>\n",
       "      <td>-0.952437</td>\n",
       "      <td>-1.733414</td>\n",
       "      <td>0.502079</td>\n",
       "      <td>0.567242</td>\n",
       "      <td>0.285880</td>\n",
       "      <td>0.366120</td>\n",
       "      <td>stable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>2.364034</td>\n",
       "      <td>2.842030</td>\n",
       "      <td>8.776391</td>\n",
       "      <td>1.008906</td>\n",
       "      <td>4.299976</td>\n",
       "      <td>-1.380719</td>\n",
       "      <td>-0.943884</td>\n",
       "      <td>-1.975373</td>\n",
       "      <td>0.487838</td>\n",
       "      <td>0.986505</td>\n",
       "      <td>0.149286</td>\n",
       "      <td>0.145984</td>\n",
       "      <td>stable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>9.631511</td>\n",
       "      <td>3.994398</td>\n",
       "      <td>2.757071</td>\n",
       "      <td>7.821347</td>\n",
       "      <td>2.514755</td>\n",
       "      <td>-0.966330</td>\n",
       "      <td>-0.649915</td>\n",
       "      <td>-0.898510</td>\n",
       "      <td>0.365246</td>\n",
       "      <td>0.587558</td>\n",
       "      <td>0.889118</td>\n",
       "      <td>0.818391</td>\n",
       "      <td>unstable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>6.530527</td>\n",
       "      <td>6.781790</td>\n",
       "      <td>4.349695</td>\n",
       "      <td>8.673138</td>\n",
       "      <td>3.492807</td>\n",
       "      <td>-1.390285</td>\n",
       "      <td>-1.532193</td>\n",
       "      <td>-0.570329</td>\n",
       "      <td>0.073056</td>\n",
       "      <td>0.505441</td>\n",
       "      <td>0.378761</td>\n",
       "      <td>0.942631</td>\n",
       "      <td>unstable</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          tau1      tau2      tau3      tau4        p1        p2        p3  \\\n",
       "0     2.959060  3.079885  8.381025  9.780754  3.763085 -0.782604 -1.257395   \n",
       "1     9.304097  4.902524  3.047541  1.369357  5.067812 -1.940058 -1.872742   \n",
       "2     8.971707  8.848428  3.046479  1.214518  3.405158 -1.207456 -1.277210   \n",
       "3     0.716415  7.669600  4.486641  2.340563  3.963791 -1.027473 -1.938944   \n",
       "4     3.134112  7.608772  4.943759  9.857573  3.525811 -1.125531 -1.845975   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "9995  2.930406  9.487627  2.376523  6.187797  3.343416 -0.658054 -1.449106   \n",
       "9996  3.392299  1.274827  2.954947  6.894759  4.349512 -1.663661 -0.952437   \n",
       "9997  2.364034  2.842030  8.776391  1.008906  4.299976 -1.380719 -0.943884   \n",
       "9998  9.631511  3.994398  2.757071  7.821347  2.514755 -0.966330 -0.649915   \n",
       "9999  6.530527  6.781790  4.349695  8.673138  3.492807 -1.390285 -1.532193   \n",
       "\n",
       "            p4        g1        g2        g3        g4     stabf  \n",
       "0    -1.723086  0.650456  0.859578  0.887445  0.958034  unstable  \n",
       "1    -1.255012  0.413441  0.862414  0.562139  0.781760    stable  \n",
       "2    -0.920492  0.163041  0.766689  0.839444  0.109853  unstable  \n",
       "3    -0.997374  0.446209  0.976744  0.929381  0.362718  unstable  \n",
       "4    -0.554305  0.797110  0.455450  0.656947  0.820923  unstable  \n",
       "...        ...       ...       ...       ...       ...       ...  \n",
       "9995 -1.236256  0.601709  0.779642  0.813512  0.608385  unstable  \n",
       "9996 -1.733414  0.502079  0.567242  0.285880  0.366120    stable  \n",
       "9997 -1.975373  0.487838  0.986505  0.149286  0.145984    stable  \n",
       "9998 -0.898510  0.365246  0.587558  0.889118  0.818391  unstable  \n",
       "9999 -0.570329  0.073056  0.505441  0.378761  0.942631  unstable  \n",
       "\n",
       "[10000 rows x 13 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(columns = 'stab')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X y Split\n",
    "\n",
    "X = df.drop(['stabf'],axis = 1)\n",
    "y = df['stabf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Test Split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, train_size = 0.8, test_size = 0.2, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " (8000, 12) \n",
      " (2000, 12) \n",
      " (8000,) \n",
      " (2000,)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" ,X_train.shape,\"\\n\" , X_test.shape,\"\\n\" ,y_train.shape,\"\\n\" , y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tau1</th>\n",
       "      <th>tau2</th>\n",
       "      <th>tau3</th>\n",
       "      <th>tau4</th>\n",
       "      <th>p1</th>\n",
       "      <th>p2</th>\n",
       "      <th>p3</th>\n",
       "      <th>p4</th>\n",
       "      <th>g1</th>\n",
       "      <th>g2</th>\n",
       "      <th>g3</th>\n",
       "      <th>g4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.367327</td>\n",
       "      <td>-0.986042</td>\n",
       "      <td>0.650447</td>\n",
       "      <td>1.547527</td>\n",
       "      <td>-0.291490</td>\n",
       "      <td>0.061535</td>\n",
       "      <td>1.293862</td>\n",
       "      <td>-0.845074</td>\n",
       "      <td>0.160918</td>\n",
       "      <td>0.339859</td>\n",
       "      <td>0.585568</td>\n",
       "      <td>0.492239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.064659</td>\n",
       "      <td>0.089437</td>\n",
       "      <td>1.035079</td>\n",
       "      <td>-1.641494</td>\n",
       "      <td>0.619865</td>\n",
       "      <td>-0.067235</td>\n",
       "      <td>-1.502925</td>\n",
       "      <td>0.486613</td>\n",
       "      <td>-0.293143</td>\n",
       "      <td>-1.558488</td>\n",
       "      <td>1.429649</td>\n",
       "      <td>-1.443521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.467850</td>\n",
       "      <td>1.298418</td>\n",
       "      <td>-0.502536</td>\n",
       "      <td>1.166046</td>\n",
       "      <td>-0.180521</td>\n",
       "      <td>0.490603</td>\n",
       "      <td>0.682560</td>\n",
       "      <td>-0.855302</td>\n",
       "      <td>1.399350</td>\n",
       "      <td>1.451534</td>\n",
       "      <td>-1.045743</td>\n",
       "      <td>0.492489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.820081</td>\n",
       "      <td>0.529920</td>\n",
       "      <td>1.299657</td>\n",
       "      <td>-1.141975</td>\n",
       "      <td>-0.812854</td>\n",
       "      <td>-0.763632</td>\n",
       "      <td>1.521579</td>\n",
       "      <td>0.658780</td>\n",
       "      <td>-0.958319</td>\n",
       "      <td>1.361958</td>\n",
       "      <td>1.604140</td>\n",
       "      <td>0.275303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.665424</td>\n",
       "      <td>-1.425627</td>\n",
       "      <td>0.312300</td>\n",
       "      <td>0.919137</td>\n",
       "      <td>-1.614296</td>\n",
       "      <td>0.760315</td>\n",
       "      <td>1.422019</td>\n",
       "      <td>0.639243</td>\n",
       "      <td>1.676895</td>\n",
       "      <td>0.695660</td>\n",
       "      <td>1.137504</td>\n",
       "      <td>-1.312575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7995</th>\n",
       "      <td>1.551314</td>\n",
       "      <td>0.007408</td>\n",
       "      <td>-1.177640</td>\n",
       "      <td>1.016898</td>\n",
       "      <td>-0.397177</td>\n",
       "      <td>0.759820</td>\n",
       "      <td>-0.636951</td>\n",
       "      <td>0.572703</td>\n",
       "      <td>-1.209413</td>\n",
       "      <td>0.313976</td>\n",
       "      <td>-1.625728</td>\n",
       "      <td>-0.637401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7996</th>\n",
       "      <td>1.015925</td>\n",
       "      <td>-0.223483</td>\n",
       "      <td>-1.489381</td>\n",
       "      <td>-1.479078</td>\n",
       "      <td>0.451468</td>\n",
       "      <td>-0.731994</td>\n",
       "      <td>0.990355</td>\n",
       "      <td>-1.048148</td>\n",
       "      <td>-1.094647</td>\n",
       "      <td>-0.755209</td>\n",
       "      <td>0.734821</td>\n",
       "      <td>-0.304433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7997</th>\n",
       "      <td>0.657609</td>\n",
       "      <td>-0.722756</td>\n",
       "      <td>-1.405888</td>\n",
       "      <td>-0.274301</td>\n",
       "      <td>-0.012584</td>\n",
       "      <td>1.438694</td>\n",
       "      <td>-0.364266</td>\n",
       "      <td>-1.046683</td>\n",
       "      <td>1.253539</td>\n",
       "      <td>0.293100</td>\n",
       "      <td>-1.550587</td>\n",
       "      <td>0.810344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7998</th>\n",
       "      <td>-0.059316</td>\n",
       "      <td>-1.260532</td>\n",
       "      <td>-1.010471</td>\n",
       "      <td>-0.877808</td>\n",
       "      <td>-0.779769</td>\n",
       "      <td>0.828824</td>\n",
       "      <td>0.516923</td>\n",
       "      <td>0.018984</td>\n",
       "      <td>-0.182448</td>\n",
       "      <td>-0.388255</td>\n",
       "      <td>-0.726781</td>\n",
       "      <td>1.667916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7999</th>\n",
       "      <td>-1.473214</td>\n",
       "      <td>0.638438</td>\n",
       "      <td>0.250122</td>\n",
       "      <td>-0.996484</td>\n",
       "      <td>1.950944</td>\n",
       "      <td>-1.163800</td>\n",
       "      <td>-0.732842</td>\n",
       "      <td>-1.513302</td>\n",
       "      <td>1.230438</td>\n",
       "      <td>-1.174110</td>\n",
       "      <td>1.179282</td>\n",
       "      <td>0.783627</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8000 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          tau1      tau2      tau3      tau4        p1        p2        p3  \\\n",
       "0     0.367327 -0.986042  0.650447  1.547527 -0.291490  0.061535  1.293862   \n",
       "1    -0.064659  0.089437  1.035079 -1.641494  0.619865 -0.067235 -1.502925   \n",
       "2    -1.467850  1.298418 -0.502536  1.166046 -0.180521  0.490603  0.682560   \n",
       "3     0.820081  0.529920  1.299657 -1.141975 -0.812854 -0.763632  1.521579   \n",
       "4     0.665424 -1.425627  0.312300  0.919137 -1.614296  0.760315  1.422019   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "7995  1.551314  0.007408 -1.177640  1.016898 -0.397177  0.759820 -0.636951   \n",
       "7996  1.015925 -0.223483 -1.489381 -1.479078  0.451468 -0.731994  0.990355   \n",
       "7997  0.657609 -0.722756 -1.405888 -0.274301 -0.012584  1.438694 -0.364266   \n",
       "7998 -0.059316 -1.260532 -1.010471 -0.877808 -0.779769  0.828824  0.516923   \n",
       "7999 -1.473214  0.638438  0.250122 -0.996484  1.950944 -1.163800 -0.732842   \n",
       "\n",
       "            p4        g1        g2        g3        g4  \n",
       "0    -0.845074  0.160918  0.339859  0.585568  0.492239  \n",
       "1     0.486613 -0.293143 -1.558488  1.429649 -1.443521  \n",
       "2    -0.855302  1.399350  1.451534 -1.045743  0.492489  \n",
       "3     0.658780 -0.958319  1.361958  1.604140  0.275303  \n",
       "4     0.639243  1.676895  0.695660  1.137504 -1.312575  \n",
       "...        ...       ...       ...       ...       ...  \n",
       "7995  0.572703 -1.209413  0.313976 -1.625728 -0.637401  \n",
       "7996 -1.048148 -1.094647 -0.755209  0.734821 -0.304433  \n",
       "7997 -1.046683  1.253539  0.293100 -1.550587  0.810344  \n",
       "7998  0.018984 -0.182448 -0.388255 -0.726781  1.667916  \n",
       "7999 -1.513302  1.230438 -1.174110  1.179282  0.783627  \n",
       "\n",
       "[8000 rows x 12 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler_X_train = pd.DataFrame(scaler.fit_transform(X_train), columns = X_train.columns)\n",
    "scaler_X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tau1</th>\n",
       "      <th>tau2</th>\n",
       "      <th>tau3</th>\n",
       "      <th>tau4</th>\n",
       "      <th>p1</th>\n",
       "      <th>p2</th>\n",
       "      <th>p3</th>\n",
       "      <th>p4</th>\n",
       "      <th>g1</th>\n",
       "      <th>g2</th>\n",
       "      <th>g3</th>\n",
       "      <th>g4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.593951</td>\n",
       "      <td>-0.412733</td>\n",
       "      <td>1.503924</td>\n",
       "      <td>1.116943</td>\n",
       "      <td>0.403423</td>\n",
       "      <td>-1.492971</td>\n",
       "      <td>-0.785033</td>\n",
       "      <td>1.566781</td>\n",
       "      <td>-0.901007</td>\n",
       "      <td>1.167203</td>\n",
       "      <td>-1.507330</td>\n",
       "      <td>1.084726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.202190</td>\n",
       "      <td>0.374416</td>\n",
       "      <td>-0.188800</td>\n",
       "      <td>-0.522268</td>\n",
       "      <td>-0.225967</td>\n",
       "      <td>-1.058483</td>\n",
       "      <td>0.420047</td>\n",
       "      <td>1.028627</td>\n",
       "      <td>-1.625721</td>\n",
       "      <td>-0.395660</td>\n",
       "      <td>1.414651</td>\n",
       "      <td>1.226011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.079044</td>\n",
       "      <td>-0.313745</td>\n",
       "      <td>-0.884634</td>\n",
       "      <td>0.017080</td>\n",
       "      <td>-0.943122</td>\n",
       "      <td>0.112653</td>\n",
       "      <td>0.801335</td>\n",
       "      <td>0.733004</td>\n",
       "      <td>1.457108</td>\n",
       "      <td>-1.438495</td>\n",
       "      <td>0.651821</td>\n",
       "      <td>-1.682168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.083120</td>\n",
       "      <td>-1.107327</td>\n",
       "      <td>0.372805</td>\n",
       "      <td>-1.708152</td>\n",
       "      <td>0.753990</td>\n",
       "      <td>-1.637972</td>\n",
       "      <td>0.403805</td>\n",
       "      <td>-0.088036</td>\n",
       "      <td>0.083322</td>\n",
       "      <td>-1.672322</td>\n",
       "      <td>-0.357714</td>\n",
       "      <td>1.055865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.873921</td>\n",
       "      <td>1.438466</td>\n",
       "      <td>0.086662</td>\n",
       "      <td>1.715037</td>\n",
       "      <td>-0.153880</td>\n",
       "      <td>-0.007015</td>\n",
       "      <td>-0.197053</td>\n",
       "      <td>0.472315</td>\n",
       "      <td>0.136549</td>\n",
       "      <td>-1.469731</td>\n",
       "      <td>0.956396</td>\n",
       "      <td>-0.819727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>1.119679</td>\n",
       "      <td>-0.675220</td>\n",
       "      <td>-1.382912</td>\n",
       "      <td>1.287865</td>\n",
       "      <td>0.249565</td>\n",
       "      <td>-0.803325</td>\n",
       "      <td>0.734497</td>\n",
       "      <td>-0.369263</td>\n",
       "      <td>0.485786</td>\n",
       "      <td>-0.115528</td>\n",
       "      <td>-1.264683</td>\n",
       "      <td>-1.283117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>-1.077913</td>\n",
       "      <td>-0.808691</td>\n",
       "      <td>1.033449</td>\n",
       "      <td>0.337636</td>\n",
       "      <td>-0.166587</td>\n",
       "      <td>0.340913</td>\n",
       "      <td>0.988085</td>\n",
       "      <td>-1.035753</td>\n",
       "      <td>0.952386</td>\n",
       "      <td>0.892766</td>\n",
       "      <td>-1.062502</td>\n",
       "      <td>-1.094114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>0.947825</td>\n",
       "      <td>-1.663727</td>\n",
       "      <td>-1.653920</td>\n",
       "      <td>0.532665</td>\n",
       "      <td>-1.518329</td>\n",
       "      <td>1.590144</td>\n",
       "      <td>0.091613</td>\n",
       "      <td>0.974455</td>\n",
       "      <td>-1.233963</td>\n",
       "      <td>0.126391</td>\n",
       "      <td>0.573445</td>\n",
       "      <td>1.319350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>-1.120235</td>\n",
       "      <td>0.193979</td>\n",
       "      <td>-0.237805</td>\n",
       "      <td>0.421570</td>\n",
       "      <td>-1.162671</td>\n",
       "      <td>0.738702</td>\n",
       "      <td>0.027367</td>\n",
       "      <td>1.265833</td>\n",
       "      <td>1.524336</td>\n",
       "      <td>0.794087</td>\n",
       "      <td>-1.362323</td>\n",
       "      <td>-0.801971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>-1.377640</td>\n",
       "      <td>1.511867</td>\n",
       "      <td>0.282651</td>\n",
       "      <td>1.510837</td>\n",
       "      <td>0.648241</td>\n",
       "      <td>-1.486786</td>\n",
       "      <td>-0.781586</td>\n",
       "      <td>1.130007</td>\n",
       "      <td>0.493337</td>\n",
       "      <td>-0.917497</td>\n",
       "      <td>0.002950</td>\n",
       "      <td>1.189023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          tau1      tau2      tau3      tau4        p1        p2        p3  \\\n",
       "0     0.593951 -0.412733  1.503924  1.116943  0.403423 -1.492971 -0.785033   \n",
       "1     0.202190  0.374416 -0.188800 -0.522268 -0.225967 -1.058483  0.420047   \n",
       "2    -1.079044 -0.313745 -0.884634  0.017080 -0.943122  0.112653  0.801335   \n",
       "3    -0.083120 -1.107327  0.372805 -1.708152  0.753990 -1.637972  0.403805   \n",
       "4     0.873921  1.438466  0.086662  1.715037 -0.153880 -0.007015 -0.197053   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1995  1.119679 -0.675220 -1.382912  1.287865  0.249565 -0.803325  0.734497   \n",
       "1996 -1.077913 -0.808691  1.033449  0.337636 -0.166587  0.340913  0.988085   \n",
       "1997  0.947825 -1.663727 -1.653920  0.532665 -1.518329  1.590144  0.091613   \n",
       "1998 -1.120235  0.193979 -0.237805  0.421570 -1.162671  0.738702  0.027367   \n",
       "1999 -1.377640  1.511867  0.282651  1.510837  0.648241 -1.486786 -0.781586   \n",
       "\n",
       "            p4        g1        g2        g3        g4  \n",
       "0     1.566781 -0.901007  1.167203 -1.507330  1.084726  \n",
       "1     1.028627 -1.625721 -0.395660  1.414651  1.226011  \n",
       "2     0.733004  1.457108 -1.438495  0.651821 -1.682168  \n",
       "3    -0.088036  0.083322 -1.672322 -0.357714  1.055865  \n",
       "4     0.472315  0.136549 -1.469731  0.956396 -0.819727  \n",
       "...        ...       ...       ...       ...       ...  \n",
       "1995 -0.369263  0.485786 -0.115528 -1.264683 -1.283117  \n",
       "1996 -1.035753  0.952386  0.892766 -1.062502 -1.094114  \n",
       "1997  0.974455 -1.233963  0.126391  0.573445  1.319350  \n",
       "1998  1.265833  1.524336  0.794087 -1.362323 -0.801971  \n",
       "1999  1.130007  0.493337 -0.917497  0.002950  1.189023  \n",
       "\n",
       "[2000 rows x 12 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler_X_test = pd.DataFrame(scaler.transform(X_test), columns = X_test.columns)\n",
    "scaler_X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. What is the accuracy on the test set using the LGBM classifier? In 4 decimal places."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9395"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_gbm = lgbm.LGBMClassifier(random_state=1)\n",
    "\n",
    "l_gbm.fit(scaler_X_train,y_train)\n",
    "\n",
    "l_gbm_predict  = l_gbm.predict(scaler_X_test)\n",
    "\n",
    "round(accuracy_score(y_test, l_gbm_predict),4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Find the feature importance using the optimal ExtraTreesClassifier model. Which features are the most and least important respectively?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ExtraTreesClassifier(random_state=1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "et_class = ExtraTreesClassifier(random_state = 1)\n",
    "\n",
    "et_class.fit(scaler_X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tau2</th>\n",
       "      <td>0.118445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tau1</th>\n",
       "      <td>0.117397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tau4</th>\n",
       "      <td>0.115466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tau3</th>\n",
       "      <td>0.113169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>g3</th>\n",
       "      <td>0.096883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>g4</th>\n",
       "      <td>0.094019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>g2</th>\n",
       "      <td>0.093676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>g1</th>\n",
       "      <td>0.089783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p3</th>\n",
       "      <td>0.040706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p4</th>\n",
       "      <td>0.040579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p2</th>\n",
       "      <td>0.040371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p1</th>\n",
       "      <td>0.039507</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0\n",
       "tau2  0.118445\n",
       "tau1  0.117397\n",
       "tau4  0.115466\n",
       "tau3  0.113169\n",
       "g3    0.096883\n",
       "g4    0.094019\n",
       "g2    0.093676\n",
       "g1    0.089783\n",
       "p3    0.040706\n",
       "p4    0.040579\n",
       "p2    0.040371\n",
       "p1    0.039507"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ext=pd.DataFrame(et_class.feature_importances_, index = ['tau1', 'tau2', \n",
    "                                                         'tau3', 'tau4', \n",
    "                                                         'p1', 'p2', 'p3', \n",
    "                                                         'p4', 'g1', 'g2',\n",
    "                                                         'g3', 'g4']).sort_values(by=0,ascending=False)\n",
    "ext\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer :- tau2,p1**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Using the ExtraTreesClassifier as your estimator with cv=5, n_iter=10, scoring = 'accuracy', <br>n_jobs = -1, verbose = 1 and random_state = 1. What are the best hyperparameters from the randomized search CV?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = [100, 300, 500, 1000]    \n",
    "min_samples_split = [7, 5, 2, 2]\n",
    "min_samples_leaf = [4, 6, 8, 8]\n",
    "max_features = [None,'auto','log2',None] \n",
    "hyperparameter = {'n_estimators': n_estimators,\n",
    "                       'min_samples_split': min_samples_split,\n",
    "                       'min_samples_leaf': min_samples_leaf,\n",
    "                       'max_features': max_features}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:  1.4min finished\n"
     ]
    }
   ],
   "source": [
    "R_search = RandomizedSearchCV(estimator = et_class, param_distributions= hyperparameter,\n",
    "                              random_state=1,cv = 5, n_iter=10,scoring='accuracy',n_jobs=-1, verbose=1)\n",
    "search = R_search.fit(scaler_X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 1000,\n",
       " 'min_samples_split': 2,\n",
       " 'min_samples_leaf': 6,\n",
       " 'max_features': None}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. What is the accuracy on the test set using the XGboost classifier? In 4 decimal places. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:12:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9455"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg_boost = XGBClassifier(random_state =1)\n",
    "xg_boost.fit(scaler_X_train, y_train)\n",
    "xg_predict = xg_boost.predict(scaler_X_test)\n",
    "round(accuracy_score(y_test,xg_predict),4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. What other hyperparameter optimization method can you try apart from Random Search?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:- Grid Search**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. You are building a classifier and the accuracy is poor on both the training and test sets. Which would you use to try to improve the performance?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:- Boosting**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. You are working on a spam classification system using regularized logistic regression. “Spam” is a positive class (y = 1) and “not spam” is the negative class (y = 0). You have trained your classifier and there are n = 1700 examples in the test set. The confusion matrix of predicted class vs. actual class is: What is the F1 score of this classifier?"
   ]
  },
  {
   "attachments": {
    "hamoye%20stage%20c.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![hamoye%20stage%20c.png](attachment:hamoye%20stage%20c.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer :- 0.2635**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Which of the following metric is generally NOT useful for a classification problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:- RMSE Value**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Jack is working on classification modelling. While evaluating the model, he saw that the difference between test and training error is a big positive number with a low training error. Which of the following, is he currently facing?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:- Overfitting**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. The ROC curve was generated from a classification algorithm. What can we say about this classifier?"
   ]
  },
  {
   "attachments": {
    "hamoye%20satge%20c%202.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![hamoye%20satge%20c%202.png](attachment:hamoye%20satge%20c%202.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:- The model has no discrimination capacity to differentiate between the positive and the negative class**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. A classifier predicts if insurance claims are fraudulent or not. The cost of paying a fraudulent claim is higher than the cost of investigating a claim that is suspected to be fraudulent. Which metric should we use to evaluate this classifier?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:- Recall**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12. What is the accuracy on the test set using the random forest classifier? In 4 decimal places."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=1)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_forest = RandomForestClassifier(random_state=1)\n",
    "r_forest.fit(scaler_X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.929"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_predict = r_forest.predict(scaler_X_test)\n",
    "round(accuracy_score(y_test, rf_predict),4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13. What is the entropy of the target variable if its actual values are given as:<br>[1,0,1,1,0,1,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:- - 3/7 log(3/7) - 4/7 log(4/7)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14. Which of these is not a good metric for evaluating classification algorithms for data with imbalanced class problems?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:- Accuracy**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15. According to a use-case, in a certain ML task, a false positive is six times costlier than a false negative. You, as a Data Scientist, trained 4 models, to solve the use case.<br>Keep the following evaluation criteria in mind:<br><br>1) Must have a recall rate of at least 80% <br>2) Must have a false positive rate of 8% or less <br>3) Must minimize business costs<br><br>After creating each binary classification model, you generated the corresponding confusion matrix. Which confusion matrix represents the model that satisfies the requirements? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:- TN = 96%, FP = 4%, FN = 10%, TP = 90%**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 16. Train a new ExtraTreesClassifier Model with the new Hyperparameters from the RandomizedSearchCV (with random_state = 1). Is the accuracy of the new optimal model higher or lower than the initial ExtraTreesClassifier model with no hyperparameter tuning?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.928"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "et_class = ExtraTreesClassifier(random_state = 1)\n",
    "\n",
    "et_class.fit(scaler_X_train,y_train)\n",
    "\n",
    "et_class_predict  = et_class.predict(scaler_X_test)\n",
    "\n",
    "round(accuracy_score(y_test, et_class_predict),4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.932"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "et_class = ExtraTreesClassifier(random_state = 1, n_estimators = 1000, min_samples_split = 2,\n",
    "                                min_samples_leaf = 6, max_features = None)\n",
    "\n",
    "et_class.fit(scaler_X_train,y_train)\n",
    "\n",
    "et_class_predict  = et_class.predict(scaler_X_test)\n",
    "\n",
    "round(accuracy_score(y_test, et_class_predict),4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:- Higher**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 17. A medical company is building a model to predict the occurrence of thyroid cancer. The training data contains 900 negative instances (people who don't have cancer) and 100 positive instances. The resulting model has 90% accuracy, but extremely poor recall. What steps can be used to improve the model's performance? (SELECT TWO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:- <br>Collect more data for the positive case<br>Generate synthetic samples/data using SMOTE**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 18. A random forest classifier was used to classify handwritten digits 0-9 into the numbers they were intended to represent. The confusion matrix below was generated from the results. Based on the matrix, which number was predicted with the least accuracy?"
   ]
  },
  {
   "attachments": {
    "hamoye%20stage%20c%203.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![hamoye%20stage%20c%203.png](attachment:hamoye%20stage%20c%203.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:- 8**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 19. You are developing a machine learning classification algorithm that categorizes handwritten digits 0-9 into the numbers they represent. How should you pre-process the label data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:- One-hot encoding**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 20. Why do we use weak learners in boosting, instead if strong learners?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:- To prevent overfitting**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# THANK YOU!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
